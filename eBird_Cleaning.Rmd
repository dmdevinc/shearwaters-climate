---
title: "eBird Data Cleaning Script"
author: "Danielle D."
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 2
    theme: flatly
---

# Introduction

Community science data including date, time, effort, and counts of sooty shearwater 
(SOSH) and pink-footed shearwater (PFSH) in the Monterey and Bodega 
Bay (or Sonoma county) areas from January 1st, 2015 - November 30th, 2025.

Bird observation data sourced from the eBird Basic Dataset (Cornell Lab of 
Ornithology). Used under the Creative Commons Attribution, Non-Commercial 
license.
    eBird Basic Dataset. Version: 2025. 
    Cornell Lab of Ornithology, Ithaca, New York.
    https://ebird.org/data/download.
  
# Loading Workspace & Set Up

```{r}
# packages
library(readr) # read data
library(janitor) # standardize column names
library(tidyverse) # data manipulation
library(lubridate) # date handling
library(ggplot2) # plotting
library(sf) # map locality
```

## Reading in the Data

```{r}
# Load --

# use "here" to manage raw files housed out of project (too large for GitHub)
library(here)

# path to raw data
raw_data_dir <- "~/Desktop/R/Shearwater raw data/"

# load data for each species in each area
pfsh.monterey <- read_delim(
  file.path(
    raw_data_dir,
    "ebd_US-CA-053_pifshe_201501_202511_smp_relOct-2025",
    "ebd_US-CA-053_pifshe_201501_202511_smp_relOct-2025.txt"
  ),
  delim = "\t",
  show_col_types = FALSE
)

sosh.monterey <- read_delim(
  file.path(
    raw_data_dir,
    "ebd_US-CA-053_sooshe_201501_202511_smp_relNov-2025",
    "ebd_US-CA-053_sooshe_201501_202511_smp_relNov-2025.txt"
  ),
  delim = "\t",
  show_col_types = FALSE
)

pfsh.sonoma <- read_delim(
  file.path(
    raw_data_dir,
    "ebd_US-CA-097_pifshe_smp_relNov-2025",
    "ebd_US-CA-097_pifshe_smp_relNov-2025.txt"
  ),
  delim = "\t",
  show_col_types = FALSE
)

sosh.sonoma <- read_delim(
  file.path(
    raw_data_dir,
    "ebd_US-CA-097_sooshe_201501_202511_smp_relNov-2025",
    "ebd_US-CA-097_sooshe_201501_202511_smp_relNov-2025.txt"
  ),
  delim = "\t",
  show_col_types = FALSE
)
```
## Create Master Dataframe

```{r}
# Combine --

# combine the above dataframes
combined <- rbind(pfsh.monterey, sosh.monterey, pfsh.sonoma, sosh.sonoma)

# standardize column names with janitor package 
combined <- combined %>%
  janitor::clean_names()

# check parsing issue from above chunk - not a big deal, don't need this column
problems(combined)

# pull columns of interest to create master
bird_master <- combined %>%
  select(state_code, county, locality, locality_id, latitude, longitude, 
         last_edited_date, common_name, observation_count, observation_type, 
         duration_minutes, effort_distance_km, number_observers, observer_id, group_identifier)

# bird_master # check

# make numeric columns numeric and set date class
bird_master <- bird_master %>%
  mutate(observation_count = as.numeric(observation_count)) %>%
  mutate(duration_minutes = as.numeric(duration_minutes)) %>%
  mutate(effort_distance_km = as.numeric(effort_distance_km)) %>%
  mutate(last_edited_date = as.Date(last_edited_date)) 

```

# Integrity Analysis

```{r}
# Explore --

# 1. County - expect two options
unique_county <- unique(bird_master$county)
unique_county
# ok - only two options

# 2. Locality - generate a list
unique_locality <- unique(bird_master$locality)
# unique_locality
# map - check all locality points look normal

# 3. Date - check range
date_range <- range(bird_master$last_edited_date, na.rm = TRUE)
date_range
# remove - some dates outside desired range

# 4. Species - expect two options
unique_species <- unique(bird_master$common_name)
unique_species
# ok - only two options

# 5. Counts - check high/low counts
summary(bird_master$observation_count)
# identify - none go below 0, but likely outliers with high max, determine if
# they should be removed later

# 6. Observation type - check options
unique_type <- unique(bird_master$observation_type)
unique_type
# remove - historical data - lacking confidence in effort details
#          incidental - birding wasn't primary purpose
#          banding - sample sizes different from incidental sightings
# keep - travelling / stationary / and pelagic but look at pelagic type separate

# 7. Effort duration (minutes) and distance (km) -
summary(bird_master$duration_minutes)
summary(bird_master$effort_distance_km)
# ok - keep all for now but low duration/distance = less confidence in entry

# 9. Groups - check for duplicates
dup_groups <- bird_master %>%
  mutate(is_dup = duplicated(group_identifier)) %>%  # use the column directly
  filter(is_dup) %>%
  select(-is_dup)
nrow(dup_groups)
# remove - duplicated groups, as these are repeat counts
```

## Explore Further - Locality and Counts

```{r}
# Locality -- quick map using lat/long

# Convert to sf
bird_sf <- bird_master %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326)

# World/US map background
world <- ne_countries(scale = "medium", returnclass = "sf")

# Plot from Bodega Bay to Monterey Bay
ggplot() +
  geom_sf(data = world, fill = "gray95", color = "gray80") +
  geom_sf(data = bird_sf, aes(color = county), size = 1) +
  coord_sf(xlim = c(-125, -120.5), ylim = c(34.9, 38.9)) +
  theme_minimal() +
  labs(
    title = "Shearwater Checklist Locations"
  )

# plot Sonoma county
ggplot() +
  geom_sf(data = world, fill = "gray95", color = "gray80") +
  geom_sf(data = bird_sf, aes(color = locality), size = 1) +
  coord_sf(xlim = c(-124.5, -122.7), ylim = c(37.8, 38.9)) +
  theme_minimal() +
  labs(
    title = "Sonoma County Checklists"
  ) +
  theme(
    legend.position = "none"
  )

# plot Monterey county
ggplot() +
  geom_sf(data = world, fill = "gray95", color = "gray80") +
  geom_sf(data = bird_sf, aes(color = locality), size = 1) +
  coord_sf(xlim = c(-124, -120), ylim = c(34.9, 37)) +
  theme_minimal() +
  labs(
    title = "Monterey Bay Checklists"
  ) +
  theme(
    legend.position = "none"
  )

# the localities look fine for now, there are no points in unexpected places
```

```{r}
# Counts -- graph and identify outliers

# plot
ggplot(bird_master, aes(x = observation_count)) +
  geom_histogram(bins = 50) +
  scale_x_log10() # use log if counts span several orders of magnitude

# Add a log-transformed count first to compress values so skew matters less
bird_master <- bird_master %>%
  mutate(log_count = log10(observation_count + 1))  # +1 to handle zeros

# Compute robust IQR on log-transformed counts
Q1 <- quantile(bird_master$log_count, 0.25, na.rm = TRUE)
Q3 <- quantile(bird_master$log_count, 0.75, na.rm = TRUE)
IQR_val <- Q3 - Q1

lower_bound <- Q1 - 1.5 * IQR_val
upper_bound <- Q3 + 1.5 * IQR_val

# Flag outliers
outliers <- bird_master %>%
  filter(log_count < lower_bound | log_count > upper_bound)

# Quick check
nrow(outliers)

# ---

# The graph shows some particularly high counts, lets check

# flag all unusually high counts, e.g., over 100,000
extreme_counts <- bird_master %>%
  filter(observation_count > 200000) %>%
  select(last_edited_date, county, observation_count, locality, observer_id, group_identifier)

# view them
extreme_counts

# check group names
unique(extreme_counts$group_identifier)

# only three groups make up these counts, lets remove them
```

# Changes to Data Based on Integrity Analyses

```{r}
# Clean -- 

# Combined cleaning pipelines
bird_master_clean <- bird_master %>%
  # 1. Dates - standardize formats and select range
  mutate(last_edited_date = as.Date(last_edited_date)) %>%
  filter(last_edited_date >= as.Date("2015-01-01") & 
         last_edited_date <= as.Date("2024-12-31")) %>%
  
  # 2. Counts - identify outliers, remove NAs
  mutate(is_outlier = log_count < lower_bound | log_count > upper_bound) %>%
  # Filter rows
  filter(
    !is.na(observation_count),                 # remove missing counts
    observation_count <= 10000 | is.na(observation_count)  # cap very high counts
  ) %>%

  
  # 3. Observation Type - remove unwanted types
  filter(observation_type %in% c("Stationary", "Traveling", "eBird Pelagic Protocol")) %>%
  
  # 4. Effort - remove NAs
  # note shorter distance/duration = less confidence
  filter(!is.na(duration_minutes), !is.na(effort_distance_km)) %>%
  
  # 5. Groups - remove duplicates
  distinct(group_identifier, .keep_all = TRUE)

# Check resulting date range
range(bird_master_clean$last_edited_date, na.rm = TRUE)
```

# Explore Clean Data

```{r}
# Scatter Plot --
# gather the max counts per day per county 
# note: can't sum the counts daily because observers count the same birds

# gather counts
bird_master_day <- bird_master_clean %>%
  group_by(last_edited_date, county) %>%
  summarize(
    daily_max = max(observation_count, na.rm = TRUE),
    .groups = "drop"
  )

# use to display graphs side by side
library(patchwork)

# filter out days with zero counts
bird_master_day_nonzero <- bird_master_day %>%
  filter(daily_max > 0)

# 1 Combined counties plot
p_combined <- ggplot(bird_master_day_nonzero, 
                     aes(x = last_edited_date, y = daily_max, color = county)) +
  geom_point(alpha = 0.6, size = 2) +
  geom_line() +
  labs(
    x = "",
    y = "Total Observations",
    color = "County",
    title = "Shearwater Observations - All Counties"
  ) +
  theme_minimal()

# 2 Monterey only
p_monterey <- bird_master_day_nonzero %>%
  filter(county == "Monterey") %>%
  ggplot(aes(x = last_edited_date, y = daily_max)) +
  geom_point(alpha = 0.6, size = 2, color = "steelblue") +
  geom_line(color = "steelblue") +
  labs(
    x = "Date",
    y = "Total Observations",
    title = "Monterey County"
  ) +
  theme_minimal()

# 3 Sonoma only
p_sonoma <- bird_master_day_nonzero %>%
  filter(county == "Sonoma") %>%
  ggplot(aes(x = last_edited_date, y = daily_max)) +
  geom_point(alpha = 0.6, size = 2, color = "tomato") +
  geom_line(color = "tomato") +
  labs(
    x = "Date",
    y = " ",
    title = "Sonoma County"
  ) +
  theme_minimal()

# Combine Monterey and Sonoma side by side
p_combined / (p_monterey | p_sonoma)
```

```{r}
# Density - Plot

# get year and day
density <- bird_master_clean %>%
  mutate(
    last_edited_date = as.Date(last_edited_date),
    year = year(last_edited_date),
    day_of_year = yday(last_edited_date)
  ) %>%
  filter(year >= 2015)

#plot
ggplot(density, aes(x = day_of_year, fill = county, color = county)) +
  geom_density(alpha = 0.3) +
  facet_wrap(~ year, ncol = 5) +
  labs(
    x = "Day of Year",
    y = "Density",
    title = "Seasonal Distribution of Shearwater Observations by Year"
  ) +
  theme_minimal()
```

```{r}
# Brainstorm chunk....

# To do:

# 1) Max counts
# I arbitrarily made the max count 10,000 just because it made better visuals
# Think about this further, find 95th percentile and remove all above it?

# 2) Visualize
# Think about cool ways to visualize this data

# 3) NOAA data
# Find and download NOAA data and clean in the same manner
```



