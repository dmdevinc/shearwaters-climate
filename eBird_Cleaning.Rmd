---
title: "eBird Data Cleaning Script"
author: "Danielle D."
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 2
    theme: flatly
---

# Introduction

This data included date, time, and count of individuals of sooty shearwater 
(SOSH) and pink-footed shearwater (PFSH) sightings in the Monterey and Bodega 
Bay (Sonoma county) areas from January 1st, 2015 - November 30th, 2025.

Bird observation data sourced from the eBird Basic Dataset (Cornell Lab of 
Ornithology). Used under the Creative Commons Attribution-NonCommercial license.

  eBird Basic Dataset. Version: 2025. 
  Cornell Lab of Ornithology, Ithaca, New York.
  https://ebird.org/data/download.
  
# Loading Workspace & Set Up

```{r}
# packages used
library(readr) # read data
library(tidyverse) # data manipulation
library(janitor) # standardize column names
library(lubridate) # easier date handling
library(ggplot2) # plotting
```

## Reading in the Data

```{r}
# Load --

# use "here" to manage raw files housed out of project (too large for GitHub)
library(here)

# path to raw data
raw_data_dir <- "~/Desktop/R/Shearwater raw data/"

# load data for each species in each area
pfsh.monterey <- read_delim(
  file.path(
    raw_data_dir,
    "ebd_US-CA-053_pifshe_201501_202511_smp_relOct-2025",
    "ebd_US-CA-053_pifshe_201501_202511_smp_relOct-2025.txt"
  ),
  delim = "\t",
  show_col_types = FALSE
)

sosh.monterey <- read_delim(
  file.path(
    raw_data_dir,
    "ebd_US-CA-053_sooshe_201501_202511_smp_relNov-2025",
    "ebd_US-CA-053_sooshe_201501_202511_smp_relNov-2025.txt"
  ),
  delim = "\t",
  show_col_types = FALSE
)

pfsh.sonoma <- read_delim(
  file.path(
    raw_data_dir,
    "ebd_US-CA-097_pifshe_smp_relNov-2025",
    "ebd_US-CA-097_pifshe_smp_relNov-2025.txt"
  ),
  delim = "\t",
  show_col_types = FALSE
)

sosh.sonoma <- read_delim(
  file.path(
    raw_data_dir,
    "ebd_US-CA-097_sooshe_201501_202511_smp_relNov-2025",
    "ebd_US-CA-097_sooshe_201501_202511_smp_relNov-2025.txt"
  ),
  delim = "\t",
  show_col_types = FALSE
)
```
## Create Master Dataframe

```{r}
# Combine --

# first, combine the above dataframes
combined <- rbind(pfsh.monterey, sosh.monterey, pfsh.sonoma, sosh.sonoma)

# standardize column names with janitor package 
combined <- combined %>%
  janitor::clean_names()

# check parsing issue from above chunk - not a big deal, don't need this column
problems(combined)

# pull columns of interest to create master
bird_master <- combined %>%
  select(state_code, county, locality, locality_id, latitude, longitude, 
         last_edited_date, common_name, observation_count, observation_type, 
         duration_minutes, effort_distance_km, number_observers, observer_id, group_identifier)

# bird_master # check

# make numeric columns numeric
bird_master <- bird_master %>%
  mutate(observation_count = as.numeric(observation_count)) %>%
  mutate(duration_minutes = as.numeric(duration_minutes)) %>%
  mutate(effort_distance_km = as.numeric(effort_distance_km)) 

```
# Integrity Analysis

```{r}
# Explore --

# County - expect two options
unique_county <- unique(bird_master$county)
unique_county
# ok - only two options

# Locality - generate a list
unique_locality <- unique(bird_master$locality)
# unique_locality
# decide - may want to map and ensure all are coastal

# Date - check range
date_range <- range(bird_master$last_edited_date, na.rm = TRUE)
date_range
# remove - some dates outside desired range

# Species - expect two options
unique_species <- unique(bird_master$common_name)
unique_species
# ok - only two options

# Counts - check high/low counts
summary(bird_master$observation_count)
# remove - none go below 0, but the max is very high

# Observation type - check options
unique_type <- unique(bird_master$observation_type)
unique_type
# decide - if there is any type I want to remove

# Effort minutes -
summary(bird_master$duration_minutes)
# decide - if there should be a max or min effort, or NAs removed

# Effort distance km -
summary(bird_master$effort_distance_km)
# decide - if there should be a max or min effort, or NAs removed

# Groups - check for duplicates
dup_groups <- bird_master %>%
  mutate(is_dup = duplicated(group_identifier)) %>%  # use the column directly
  filter(is_dup) %>%
  select(-is_dup)
nrow(dup_groups)
# remove - there are many duplicated groups
```

## Explore Further - Locality, Counts, and Effort (minutes and durations) - WORKING

Graph, summarize stats, determine what to remove before you do it

```{r}
# Locality -- map
```

```{r}
# Counts -- determine 95 percentile and graph
```

```{r}
# Effort (minutes and duration) -- determine 95 percentile and graph
```

# Changes to Data Based on Integrity Analyses - WORKING

```{r}
# Clean -- Locality
```


```{r}
# Clean -- Dates
# standardize and make sure all are within desired range

# make sure date column is in Date or POSIXct format
bird_master$last_edited_date <- as.Date(bird_master$last_edited_date)

# filter data by exactly 10 years of data (Jan. 1, 2015 - Dec. 31, 2024)
bird_master <- bird_master %>%
  filter(last_edited_date >= "2015-01-01" & last_edited_date <= "2024-12-31")

# check dates were updated
date_range <- range(bird_master$last_edited_date, na.rm = TRUE)
date_range
```

```{r}
# Clean --Counts

# determine 95 percentile

# flag all unusually high counts, e.g., over 100,000
extreme_counts <- bird_master %>%
  filter(observation_count > 200000) %>%
  select(last_edited_date, county, observation_count, locality, observer_id, group_identifier)

# view them
extreme_counts

# check group names
unique(extreme_counts$group_identifier)

# Only three groups make up all of the extreme counts. 

# remove extreme counts
bird_master_clean <- bird_master %>%
  filter(observation_count <= 200000 | is.na(observation_count))
```

```{r}
# Clean -- Observation Type
```

```{r}
# Clean -- Effort (minutes and distance)
```

```{r}
# Clean -- Groups
# remove duplicate group ids

ebird_clean <- bird_master %>%
  distinct(group_id, .keep_all = TRUE)
```

# Brain dump ... (keep for now)

```{r}
# Graph counts

# ----------------------
# gather the max counts per day per county 
# note: can't sum the counts daily because observers count the same birds
bird_master_day <- bird_master_clean %>%
  group_by(last_edited_date, county) %>%
  summarize(
    daily_max = max(observation_count, na.rm = TRUE),
    .groups = "drop"
  )

# plot - bar and points
ggplot(bird_master_day, aes(x = last_edited_date, y = daily_max, color = county)) +
  geom_line() +              # lines per county
  geom_point(alpha = 0.5) +  # optional: points for each day
  labs(
    x = "Date",
    y = "Total Observations",
    color = "County",
    title = "Shearwater Observations Over Time"
  ) +
  theme_minimal()

# ----------------------
# heat map
heat <- bird_master_clean %>%
  mutate(
    week = week(last_edited_date),
    month = month(last_edited_date, label = TRUE)
  ) %>%
  group_by(county, year, week) %>%  # or month
  summarise(weekly_max = max(max_count, na.rm = TRUE), .groups = "drop")

ggplot(heat, aes(x = week, y = factor(year), fill = weekly_max)) +
  geom_tile() +
  facet_wrap(~county) +
  scale_fill_viridis_c(option = "plasma") +
  labs(
    x = "Week of Year",
    y = "Year",
    fill = "Max Count",
    title = "Weekly Max Shearwater Counts Heatmap"
  ) +
  theme_minimal()

# ----------------------
# Prepare data for box and density plots
shearwater <- bird_master_clean %>%
  mutate(
    date = as_date(last_edited_date),
    year = year(date),
    month = month(date, label = TRUE),
    day_of_year = yday(date)
  ) %>%
  group_by(county, date, year, day_of_year) %>%  # <-- group by county + date
  summarize(
    daily_max = max(observation_count, na.rm = TRUE),
    .groups = "drop"
  )

# Boxplots per year
ggplot(shearwater, aes(x = factor(year), y = daily_max, fill = county)) +
  geom_boxplot(outlier.colour = "red", outlier.shape = 1) +
  labs(
    x = "Year",
    y = "Daily Max Count",
    fill = "County",
    title = "Distribution of Daily Max Counts per Year"
  ) +
  theme_minimal()

# Density plots per year (seasonality)
ggplot(shearwater, aes(x = day_of_year, y = ..density.., color = county, fill = county)) +
  geom_density(alpha = 0.3) +
  labs(
    x = "Day of Year",
    y = "Density of Max Counts",
    title = "Seasonal Density of Shearwater Daily Max Counts"
  ) +
  theme_minimal()

```

```{r}
# Brainstorming...

# Fix graphs above, choose most representative.

# Organize this cleaning section, don't overwrite dataframes, may want to return to unclean data. Graph as you go and include justification for removal.

# I'm noticing no observations in Monterey pre 2015... could this be no birds or something else, like eBird surged in popularity in 2020 with covid? Need to look into this further.

# Think about the goal, shiny app visualization of what? seasonality? interested in changes over time with climate variables... cool ways to visualize data... 
```

## NOAA Data

This data includes temperature, wind, sea surface temperature (sst), upwelling index, and enso index for Monterey and Bodega Bays.

Data sourced from NOAA [dataset name], accessed on [date]. NOAA data are in the public domain.

https://www.ncei.noaa.gov/products/optimum-interpolation-sst
https://www.cpc.ncep.noaa.gov
https://coastwatch.pfeg.noaa.gov/data.html
https://coastwatch.pfeg.noaa.gov/index.html

This data includes...
  - Sea surface temperature (sst) : ties to marine heatwaves, upwelling strength, and forage fish distribution
  - Wind: strong northwest wings indicate cold, productive waters
  - Upwelling Index (Bakun Index): productivity
  - ENSO indices: large scale climate patterns that affect local productivity

for Monterey and Bodega Bays.

```{r}
# weekly average? daily - too noisy
# identify anomalies
```
